{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainer 手書き文字認識(MNIST) チュートリアル\n",
    "\n",
    "(chainer 1.21.0 ver.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 必要モジュールのインポート\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTとは？\n",
    "MNISTは手書き数字の画像のデータセットです。\n",
    "![](https://www.tensorflow.org/versions/master/images/MNIST.png)\n",
    "このような画像（28px×28px）の集まりです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNISTのデータセットを読み込む\n",
    "train, test = chainer.datasets.get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 画像表示用関数\n",
    "\n",
    "def draw_digit(data):\n",
    "    \"\"\"数値の行列データを画像表示\"\"\"\n",
    "    size = 28\n",
    "    plt.figure(figsize=(2.5, 3))\n",
    "\n",
    "    X, Y = np.meshgrid(range(size),range(size))\n",
    "    Z = data.reshape(size,size)   # convert from vector to 28x28 matrix\n",
    "    Z = Z[::-1,:]             # flip vertical\n",
    "    plt.xlim(0,27)\n",
    "    plt.ylim(0,27)\n",
    "    plt.pcolor(X, Y, Z)\n",
    "    plt.gray()\n",
    "    plt.tick_params(labelbottom=\"off\")\n",
    "    plt.tick_params(labelleft=\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAC1CAYAAABMMl33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106381e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画像表示　例\n",
    "sample_data = np.array(train[1][0])\n",
    "draw_digit(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.01176471\n",
      "  0.07058824  0.07058824  0.07058824  0.49411768  0.53333336  0.68627453\n",
      "  0.10196079  0.65098041  1.          0.96862751  0.49803925  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.11764707  0.14117648  0.36862746\n",
      "  0.60392159  0.66666669  0.99215692  0.99215692  0.99215692  0.99215692\n",
      "  0.99215692  0.88235301  0.67450982  0.99215692  0.94901967  0.76470596\n",
      "  0.25098041  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.19215688\n",
      "  0.9333334   0.99215692  0.99215692  0.99215692  0.99215692  0.99215692\n",
      "  0.99215692  0.99215692  0.99215692  0.98431379  0.36470589  0.32156864\n",
      "  0.32156864  0.21960786  0.15294118  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.07058824  0.8588236   0.99215692  0.99215692  0.99215692\n",
      "  0.99215692  0.99215692  0.77647066  0.71372551  0.96862751  0.9450981   0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.3137255   0.61176473  0.41960788\n",
      "  0.99215692  0.99215692  0.80392164  0.04313726  0.          0.16862746\n",
      "  0.60392159  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.05490196  0.00392157  0.60392159  0.99215692  0.35294119  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.54509807  0.99215692  0.74509805  0.00784314\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.04313726  0.74509805  0.99215692\n",
      "  0.27450982  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.13725491\n",
      "  0.9450981   0.88235301  0.627451    0.42352945  0.00392157  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.31764707  0.94117653  0.99215692  0.99215692  0.4666667   0.09803922\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.17647059  0.72941178  0.99215692  0.99215692\n",
      "  0.58823532  0.10588236  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.0627451   0.36470589\n",
      "  0.98823535  0.99215692  0.73333335  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.97647065  0.99215692  0.97647065  0.25098041  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.18039216  0.50980395\n",
      "  0.71764708  0.99215692  0.99215692  0.81176478  0.00784314  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.15294118  0.58039218  0.89803928\n",
      "  0.99215692  0.99215692  0.99215692  0.98039222  0.71372551  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.09411766  0.44705886  0.86666673  0.99215692\n",
      "  0.99215692  0.99215692  0.99215692  0.78823537  0.30588236  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.09019608  0.25882354  0.83529419  0.99215692  0.99215692\n",
      "  0.99215692  0.99215692  0.77647066  0.31764707  0.00784314  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.07058824  0.67058825  0.8588236   0.99215692  0.99215692  0.99215692\n",
      "  0.99215692  0.76470596  0.3137255   0.03529412  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.21568629  0.67450982  0.88627458  0.99215692  0.99215692  0.99215692\n",
      "  0.99215692  0.95686281  0.52156866  0.04313726  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.53333336  0.99215692  0.99215692  0.99215692  0.83137262\n",
      "  0.52941179  0.51764709  0.0627451   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# 手書き文字画像　行列データ\n",
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このようにコンピュータ上では、画像は行列として扱われています\n",
    "![](https://www.tensorflow.org/versions/master/images/MNIST-Matrix.png)\n",
    "\n",
    "参考URL：http://tensorflow.classcat.com/2016/03/09/tensorflow-cc-mnist-for-ml-beginners/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "\n",
    "class MLP(chainer.Chain):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" ネットワークの構造を定義 \"\"\"\n",
    "        super(MLP, self).__init__(\n",
    "            l1=L.Linear(784, 1000),  # 入力784ユニット、出力1000ユニット\n",
    "            l2=L.Linear(1000, 500),  # 入力1000ユニット、出力500ユニッ\n",
    "            l3=L.Linear(500, 10),      # 入力500ユニット、出力10ユニット\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\" 計算の規則を定義 \"\"\"\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルに書いてあるコードを図にすると以下のようになります。\n",
    "\n",
    "手書き数字のデータは28px×28pxで784次元のベクトルになるので、インプットの数値の個数は784ユニットになります。\n",
    "\n",
    "アウトプットでは、１〜１０の数字である確率を出力するため10個のユニットになります。\n",
    "![](https://qiita-image-store.s3.amazonaws.com/0/50670/155b9533-4b47-0748-226c-1e3082930ed9.png)\n",
    "\n",
    "参考URL：http://qiita.com/kenmatsu4/items/7b8d24d4c5144a686412"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 活性化関数\n",
    "F.relu()は正規化線形関数(Rectified Linear Unit function)で\n",
    "\n",
    "$$\n",
    "{f(x) = \\max(0, x)\n",
    "}\n",
    "$$\n",
    "![](https://qiita-image-store.s3.amazonaws.com/0/50670/e1cc4c94-e4ae-0010-82e5-c27956b5986c.png)\n",
    "\n",
    "このような数式です。\n",
    "\n",
    "シンプルな関数なので、計算量が小さく学習スピードが速くなることがメリットです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ミニバッチのサイズを指定\n",
    "batchsize = 100\n",
    "\n",
    "# 学習の繰り返し回数（epoch）を指定\n",
    "epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 訓練のためのニューラルネットワークをセットアップする\n",
    "model = L.Classifier(MLP())\n",
    "\n",
    "# 最適化の方法を定義\n",
    "optimizer = chainer.optimizers.SGD()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データセットをイテレータの形式に変換する\n",
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           1.1102      0.504376              0.769283       0.879                     10.9824       \n",
      "\u001b[J2           0.429117    0.352206              0.887533       0.9039                    22.5195       \n",
      "\u001b[J3           0.342609    0.304576              0.90485        0.9144                    33.5296       \n",
      "\u001b[J4           0.303725    0.277295              0.914467       0.9216                    44.3066       \n",
      "\u001b[J5           0.2789      0.258589              0.92105        0.9271                    56.0953       \n",
      "\u001b[J6           0.259553    0.243513              0.926433       0.931                     71.5407       \n",
      "\u001b[J7           0.243607    0.229346              0.93175        0.9351                    82.5008       \n",
      "\u001b[J8           0.229888    0.218205              0.93555        0.9391                    93.7244       \n",
      "\u001b[J9           0.217481    0.2082                0.939083       0.9407                    107.073       \n",
      "\u001b[J10          0.206412    0.200244              0.942233       0.9434                    120.012       \n",
      "\u001b[J11          0.196249    0.189441              0.945033       0.9449                    131.811       \n",
      "\u001b[J12          0.186772    0.182379              0.947667       0.9476                    143.62        \n",
      "\u001b[J13          0.178631    0.176836              0.950183       0.9496                    155.55        \n",
      "\u001b[J14          0.170499    0.168436              0.952033       0.951                     167.071       \n",
      "\u001b[J15          0.163463    0.16352               0.9539         0.9519                    178.564       \n",
      "\u001b[J16          0.156554    0.156089              0.955717       0.9541                    190.42        \n",
      "\u001b[J17          0.150314    0.15171               0.958017       0.9556                    202.015       \n",
      "\u001b[J18          0.144371    0.146384              0.959433       0.9566                    214.295       \n",
      "\u001b[J19          0.138992    0.142607              0.961133       0.9587                    227.534       \n",
      "\u001b[J20          0.133519    0.137655              0.962633       0.96                      241.051       \n"
     ]
    }
   ],
   "source": [
    "# trainerにセットする\n",
    "updater = training.StandardUpdater(train_iter, optimizer)\n",
    "trainer = training.Trainer(updater, (epoch, 'epoch'))\n",
    "\n",
    "# epochごとに学習後の精度を評価する\n",
    "trainer.extend(extensions.Evaluator(test_iter, model))\n",
    "\n",
    "# epochごとにlogを出力する\n",
    "trainer.extend(extensions.LogReport())\n",
    "\n",
    "# logに出力する情報を指定する\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'validation/main/loss',\n",
    "                                       'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
    "\n",
    "# 進捗バーを表示する\n",
    "# trainer.extend(extensions.ProgressBar())\n",
    "\n",
    "# 構成したtrainerをもとに､学習を実行する\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 訓練済みモデルを保存する(任意)\n",
    "chainer.serializers.save_npz('mnist_model', model)\n",
    "chainer.serializers.save_npz('mnist_optimizer', optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習済みモデルで数字を予測\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAC1CAYAAABMMl33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABP1JREFUeJzt3TEorXEcxvH/ucmRDokSC4mECMlgMEkZ2JRkZzJIWRTL\nWZRTkmyyySKjMphsBgahSAjjicFCOne/v//Ve5zznPfwfj/jc+8579vt21vvfc8hlslkHKD0J+wT\nwO9HZJAjMsgRGeSIDHIlX/1hLBbj1hNZyWQysX83rmSQIzLIERnkiAxyRAY5IoMckUGOyCBHZJAj\nMsgRGeSIDHJEBjkigxyRQY7IIEdkkCMyyH358eso6OjoMNvo6KjZpqenzXZycmK209PTwMdeW1sz\n2/v7e+DX/xRcySBHZJAjMsgRGeSIDHJEBrnYVz+f7Dd9g3xmZsa7r66umi2RSKhPxznn3NDQkNmO\njo4KcmwVvkGOUBAZ5IgMckQGOSKDXGTuLqurq7375eWl2Wpra9Wn45xz7uXlxWwTExNmOzw8LMTp\n5AV3lwgFkUGOyCBHZJAjMshF5uPX6XTauy8vL5stlUqZrby83GwPDw9ma2hoCHxOVVVVZhsZGTHb\nT7q79OFKBjkigxyRQY7IIEdkkIvMs8tsnJ2dma27u9ts5+fnZuvs7Mzp2M3NzWa7vb3N6T0LiWeX\nCAWRQY7IIEdkkCMyyEXm2WU2ksmk2RYXF83W09OT92PH4/G8v2fYuJJBjsggR2SQIzLIERnkiAxy\nPCAPqK6uzmy+j0V3dXXldJy9vT2zjY+P5/SehcQDcoSCyCBHZJAjMsgRGeR4QO4xNTVlNt/Hr3P9\nqLXP8fFx3t8zbFzJIEdkkCMyyBEZ5IgMcpF5dtnW1ubd9/f3zdbS0mK2kpLC3Ijz5V7gG4gMckQG\nOSKDHJFBLjLPLtvb2717U1OT2Qp1J+kzNzdnttnZ2RDOJH+4kkGOyCBHZJAjMsgRGeQic3fpe0bp\nnHMLCwtmW1lZMVtZWVnez8mnvr6+IMcpJK5kkCMyyBEZ5IgMckQGOSKDXGT+C+N/1tfXzXZ9fW02\n32/Z9fE9XN/Y2PD+3crKykDv+dNxJYMckUGOyCBHZJAjMshF/u7S5+Dg4NuvjcXMd1u9XxZ2zrml\npSWz+X5fU2Njo9nu7++/cXbh4EoGOSKDHJFBjsggR2SQ4+4yz0pLS83mu4v8n4+PD7N9fn7mdE5h\n40oGOSKDHJFBjsggR2SQ4+4yz5LJZE6v39raMtvj42NO7xk2rmSQIzLIERnkiAxyRAa5ov21NzU1\nNWbb3t422+7urtl2dnYk5/Qv3495urq6Mls236/k194A30BkkCMyyBEZ5IgMckQGuaJ9QO77kU5j\nY2Nma21tNdvT01OgzTnnbm5uzNbX1xfoOL6fnJ3Nf1ekUimzPT8/B379T8GVDHJEBjkigxyRQY7I\nIFe0D8gHBgbM5rsb8/09n7u7O+9+cXFhtsHBQbNVVFQEOo7v39P30Nw55/r7+8329vYW6DjFigfk\nCAWRQY7IIEdkkCMyyBXt3aWP7+7S9+xxc3OzEKfjlU6nzeb7KPlvxd0lQkFkkCMyyBEZ5IgMckX7\nyVif+fl5s8XjcbMlEonA79nb22u2ycnJQK99fX012/DwcOBjRwVXMsgRGeSIDHJEBjkig9yPenaJ\n4sezS4SCyCBHZJAjMsgRGeSIDHJEBjkigxyRQY7IIEdkkCMyyBEZ5IgMckQGOSKDHJFBjsggR2SQ\nIzLIERnkiAxyRAY5IoMckUHuy2+QA/nAlQxyRAY5IoMckUGOyCD3F+Ln8unogFQ3AAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116c34e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predict →　「 3 」\n"
     ]
    }
   ],
   "source": [
    "# 学習済みモデルを使用した予測\n",
    "pred = np.array(train[10][0]).reshape(-1, 1, 28, 28)\n",
    "mnist_test = model.predictor(pred)\n",
    "\n",
    "pre_num = int(np.argmax(mnist_test.data, axis=1))\n",
    "print(\"学習済みモデルで数字を予測\")\n",
    "draw_digit(np.array(train[10][0]))\n",
    "print(\"model predict →　「 {} 」\".format(pre_num))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
